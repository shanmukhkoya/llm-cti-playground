# Project Vision â€“ LLM CTI Playground

This project is a modular, hands-on exploration of Generative AI components relevant to contact center automation and
intelligent CTI applications.

## ðŸ”¥ Goal
To deeply understand and build tools using:
- Local LLMs (TinyLLaMA via Ollama)
- Embeddings & RAG for knowledge retrieval
- Voice pipelines (Speech-to-Text & Text-to-Speech)
- Use cases like Agent Assist and Call Summarization

## Structure

The project is organized into phases:

- **Phase 1: LLM Core**
  - Run a local LLM (TinyLLaMA via Ollama)
  - Build a CLI interface to chat with the model

- **Phase 2: Chat UI**
  - Create a simple user interface (Streamlit or terminal UI)
  - Maintain LLM interaction via local API

- **Phase 3: Embeddings & RAG**
  - Ingest and embed documents
  - Use vector databases for retrieval-based QA

- **Phase 4: Speech Interfaces**
  - Add Speech-to-Text (STT) for voice input
  - Add Text-to-Speech (TTS) for voice output

- **Phase 5: Use Case Prototypes**
  - Simulate scenarios like agent assist, knowledge lookup, and summarization

## Design Goals

- Keep components modular and lightweight
- Support offline/local development where possible
- Provide clarity, reusability, and step-by-step expansion
